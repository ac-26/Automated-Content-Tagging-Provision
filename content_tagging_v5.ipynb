{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNx7J3UZWhDHR+TozBZY8Nd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ac-26/Automated-Content-Tagging-Provision/blob/main/content_tagging_v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "s3Zoho773RWc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import re\n",
        "from typing import List, Dict, Tuple\n",
        "from collections import Counter\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEncoder:\n",
        "  #initialization function\n",
        "  def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    self.model = AutoModel.from_pretrained(model_name)\n",
        "    self.model.eval()\n",
        "    print(\"Model Loaded Succesfully\")\n",
        "\n",
        "  #encodes text\n",
        "  def encode_text(self, text: str) -> np.ndarray:\n",
        "    inputs = self.tokenizer(text, return_tensors=\"pt\",truncation=True, padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "      outputs = self.model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings.numpy().flatten()"
      ],
      "metadata": {
        "id": "3XdI1bkm3c7_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TagVocabulary:\n",
        "  #initialization function\n",
        "  def __init__(self):\n",
        "    self.tags = [\n",
        "            # Content Creation\n",
        "            \"Content Writing\", \"Copywriting\", \"Blog Writing\", \"Article Writing\",\n",
        "            \"Creative Writing\", \"Technical Writing\", \"Content Strategy\",\n",
        "\n",
        "            # Marketing\n",
        "            \"Social Media Marketing\", \"Digital Marketing\", \"Email Marketing\",\n",
        "            \"Marketing Strategy\", \"Brand Marketing\", \"Influencer Marketing\",\n",
        "\n",
        "            # Social Media\n",
        "            \"Social Media\", \"Facebook Marketing\", \"Instagram Marketing\",\n",
        "            \"Twitter Marketing\", \"LinkedIn Marketing\", \"TikTok Marketing\",\n",
        "\n",
        "            # Analytics & Testing\n",
        "            \"A/B Testing\", \"Analytics\", \"Performance Tracking\", \"Data Analysis\",\n",
        "            \"Audience Research\", \"Market Research\",\n",
        "\n",
        "            # Advertising\n",
        "            \"Online Advertising\", \"Social Media Ads\", \"Google Ads\",\n",
        "            \"Facebook Ads\", \"Digital Advertising\",\n",
        "\n",
        "            # Skills & Techniques\n",
        "            \"Communication Skills\", \"Writing Skills\", \"Creative Skills\",\n",
        "            \"Marketing Skills\", \"Design Skills\",\n",
        "\n",
        "            # Strategy & Planning\n",
        "            \"Content Planning\", \"Marketing Planning\", \"Campaign Strategy\",\n",
        "            \"Audience Targeting\", \"Customer Engagement\"\n",
        "        ]\n",
        "\n",
        "    print(f\"Tag vocabulary initialized with {len(self.tags)} tags\")\n",
        "\n",
        "    #this will return list of tags in our vocabulary\n",
        "    def get_tags(self) -> List[str]:\n",
        "        return self.tags.copy()\n",
        "\n",
        "    #this will add a new tag in our vocabulary\n",
        "    def add_tag(self, new_tag: str):\n",
        "        if new_tag not in self.tags:\n",
        "            self.tags.append(new_tag)\n",
        "            print(f\"Added new tag: {new_tag}\")\n",
        "        else:\n",
        "            print(f\"Tag '{new_tag}' already exists\")"
      ],
      "metadata": {
        "id": "Ulg6UPSU6Pso"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicTagger:\n",
        "  #initializer function\n",
        "    def __init__(self):\n",
        "      self.encoder = TextEncoder()\n",
        "      self.vocabulary = TagVocabulary()\n",
        "\n",
        "      self.tag_embeddings = self._encode_all_tags()\n",
        "\n",
        "    #function to encode all tags before hand\n",
        "    def _encode_all_tags(self) -> Dict[str, np.ndarray]:\n",
        "        tag_embeddings = {}\n",
        "        for tag in self.vocabulary.tags:\n",
        "            embedding = self.encoder.encode_text(tag)\n",
        "            tag_embeddings[tag] = embedding\n",
        "\n",
        "        return tag_embeddings\n",
        "\n",
        "    #finds tags from our vocaublary that are applicable according to our text input\n",
        "    def find_matching_tags(self, input_text: str, top_k: int = 10) -> List[Tuple[str, float]]:\n",
        "        # Encode the input text\n",
        "        input_embedding = self.encoder.encode_text(input_text)\n",
        "\n",
        "        similarities = []\n",
        "\n",
        "        for tag_name, tag_embedding in self.tag_embeddings.items():\n",
        "            # Calculate cosine similarity\n",
        "            similarity = cosine_similarity(\n",
        "                input_embedding.reshape(1, -1),\n",
        "                tag_embedding.reshape(1, -1)\n",
        "            )[0][0]\n",
        "\n",
        "            similarities.append((tag_name, float(similarity)))\n",
        "\n",
        "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return similarities[:top_k]"
      ],
      "metadata": {
        "id": "vcARCTEQ6ZOb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our basic tagger\n",
        "def test_basic_tagger():\n",
        "    tagger = BasicTagger()\n",
        "\n",
        "    test_text = \"\"\"\n",
        "    Creating social media posts is a great way to hone your content writing skills.\n",
        "    Since posts are typically very short, snappy, and quick, you can easily try out\n",
        "    different styles of writing and see what people respond to. It's easy to change\n",
        "    direction and adapt if you need to tweak your writing style since social media\n",
        "    posts are typically fluid and changeable by nature. You can also practice A/B\n",
        "    testing with your social media ads—try writing two different posts and sending\n",
        "    it to similar demographics and see which one performs better.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Input text:\")\n",
        "    print(test_text)\n",
        "\n",
        "    # Find matching tags\n",
        "    matching_tags = tagger.find_matching_tags(test_text, top_k=15)\n",
        "\n",
        "    print(\"Top matching tags:\")\n",
        "    for i, (tag, score) in enumerate(matching_tags, 1):\n",
        "        print(f\"{i:2d}. {tag:<25} (Score: {score:.3f})\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_basic_tagger()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O6vyybt_o1o",
        "outputId": "035d8080-601a-4f78-95a8-430898d968f2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded Succesfully\n",
            "Tag vocabulary initialized with 40 tags\n",
            "Input text:\n",
            "\n",
            "    Creating social media posts is a great way to hone your content writing skills. \n",
            "    Since posts are typically very short, snappy, and quick, you can easily try out \n",
            "    different styles of writing and see what people respond to. It's easy to change \n",
            "    direction and adapt if you need to tweak your writing style since social media \n",
            "    posts are typically fluid and changeable by nature. You can also practice A/B \n",
            "    testing with your social media ads—try writing two different posts and sending \n",
            "    it to similar demographics and see which one performs better.\n",
            "    \n",
            "Top matching tags:\n",
            " 1. Blog Writing              (Score: 0.535)\n",
            " 2. Social Media Marketing    (Score: 0.493)\n",
            " 3. Social Media Ads          (Score: 0.490)\n",
            " 4. Social Media              (Score: 0.483)\n",
            " 5. Content Writing           (Score: 0.462)\n",
            " 6. Twitter Marketing         (Score: 0.413)\n",
            " 7. Article Writing           (Score: 0.380)\n",
            " 8. Instagram Marketing       (Score: 0.352)\n",
            " 9. Content Strategy          (Score: 0.350)\n",
            "10. Writing Skills            (Score: 0.339)\n",
            "11. Facebook Marketing        (Score: 0.328)\n",
            "12. Audience Research         (Score: 0.312)\n",
            "13. Creative Writing          (Score: 0.296)\n",
            "14. Online Advertising        (Score: 0.285)\n",
            "15. Facebook Ads              (Score: 0.276)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dynamic Tag Generation**"
      ],
      "metadata": {
        "id": "KlTi8gxagMGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KeyPhraseExtractor:\n",
        "  #initialization function\n",
        "  def __init__(self):\n",
        "      try:\n",
        "          self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "      except:\n",
        "          print(\"Please install spacy model: python -m spacy download en_core_web_sm\")\n",
        "          raise\n",
        "\n",
        "      # using Parts of Speech(POS) technique of NLP, these find patterns that make good tags\n",
        "      # these patterns help identify meaningful phrases\n",
        "      self.phrase_patterns = [\n",
        "          # single noun (e.g., \"Python\", \"Marketing\")\n",
        "          [\"NOUN\"],\n",
        "          [\"PROPN\"],  # proper nouns\n",
        "\n",
        "          # adjective + noun (e.g., \"Machine Learning\", \"Social Media\")\n",
        "          [\"ADJ\", \"NOUN\"],\n",
        "          [\"ADJ\", \"PROPN\"],\n",
        "\n",
        "          # noun + noun (e.g., \"Data Science\", \"Content Strategy\")\n",
        "          [\"NOUN\", \"NOUN\"],\n",
        "          [\"PROPN\", \"NOUN\"],\n",
        "          [\"NOUN\", \"PROPN\"],\n",
        "\n",
        "          # three-word phrases (e.g., \"Natural Language Processing\")\n",
        "          [\"ADJ\", \"NOUN\", \"NOUN\"],\n",
        "          [\"NOUN\", \"NOUN\", \"NOUN\"],\n",
        "          [\"PROPN\", \"PROPN\", \"PROPN\"],\n",
        "\n",
        "          # verb forms that work as tags (e.g., \"Programming\", \"Writing\")\n",
        "          [\"VERB\"],  # this will filter for -ing forms\n",
        "      ]\n",
        "\n",
        "      print(\"KeyPhraseExtractor initialized successfully\")\n",
        "\n",
        "\n",
        "\n",
        "  #ths extractx key phrases on the base of POS tagging done above\n",
        "  def extract_phrases(self, text: str, min_freq: int = 1) -> List[Tuple[str, int]]:\n",
        "    # Process text with spaCy\n",
        "    doc = self.nlp(text.lower())\n",
        "\n",
        "    # Store found phrases with their frequencies\n",
        "    phrase_counter = Counter()\n",
        "\n",
        "    # Extract phrases based on POS patterns\n",
        "    for sentence in doc.sents:\n",
        "      for token_idx in range(len(sentence)):\n",
        "        # Try each pattern starting from current token\n",
        "        for pattern in self.phrase_patterns:\n",
        "          if token_idx + len(pattern) <= len(sentence):\n",
        "            # Check if tokens match the pattern\n",
        "            tokens = sentence[token_idx:token_idx + len(pattern)]\n",
        "            pos_sequence = [token.pos_ for token in tokens]\n",
        "\n",
        "            if pos_sequence == pattern:\n",
        "              # Additional filters\n",
        "              phrase_tokens = []\n",
        "              valid = True\n",
        "              for token in tokens:\n",
        "                # Skip stopwords in single-word phrases\n",
        "                if len(pattern) == 1 and token.is_stop:\n",
        "                  valid = False\n",
        "                  break\n",
        "                # For verbs, only keep -ing forms (gerunds)\n",
        "                if token.pos_ == \"VERB\" and not token.text.endswith(\"ing\"):\n",
        "                  valid = False\n",
        "                  break\n",
        "                # Skip very short words\n",
        "                if len(token.text) < 3:\n",
        "                  valid = False\n",
        "                  break\n",
        "\n",
        "                phrase_tokens.append(token.text)\n",
        "\n",
        "              if valid and phrase_tokens:\n",
        "                phrase = \" \".join(phrase_tokens)\n",
        "                # Clean up the phrase\n",
        "                phrase = re.sub(r'\\s+', ' ', phrase).strip()\n",
        "                if phrase:\n",
        "                  phrase_counter[phrase] += 1\n",
        "\n",
        "        # Filter by minimum frequency and return\n",
        "    phrases = [(phrase, freq) for phrase, freq in phrase_counter.items()\n",
        "                   if freq >= min_freq]\n",
        "\n",
        "        # Sort by frequency (descending)\n",
        "    phrases.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return phrases"
      ],
      "metadata": {
        "id": "3F2iiLgcAIZH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PhraseScorer:\n",
        "    \"\"\"\n",
        "    Scores and filters extracted phrases to identify the best tags.\n",
        "    Uses multiple scoring factors to determine tag quality.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Common/generic words that make poor tags\n",
        "        self.generic_words = {\n",
        "            'way', 'ways', 'thing', 'things', 'people', 'person', 'time', 'times',\n",
        "            'place', 'places', 'day', 'days', 'year', 'years', 'good', 'bad',\n",
        "            'great', 'nice', 'sure', 'certain', 'different', 'same', 'other',\n",
        "            'new', 'old', 'high', 'low', 'large', 'small', 'long', 'short',\n",
        "            'easy', 'hard', 'simple', 'complex', 'nature', 'type', 'types',\n",
        "            'kind', 'kinds', 'lot', 'lots', 'direction', 'need', 'needs'\n",
        "        }\n",
        "\n",
        "        # Words that boost phrase importance\n",
        "        self.domain_indicators = {\n",
        "            'analysis', 'strategy', 'marketing', 'development', 'management',\n",
        "            'design', 'research', 'optimization', 'system', 'process', 'method',\n",
        "            'technique', 'approach', 'framework', 'model', 'algorithm', 'data',\n",
        "            'content', 'digital', 'social', 'media', 'online', 'software',\n",
        "            'testing', 'planning', 'writing', 'creative', 'technical'\n",
        "        }\n",
        "\n",
        "        print(\"PhraseScorer initialized successfully\")\n",
        "\n",
        "    def calculate_phrase_scores(self, phrases: List[Tuple[str, int]],\n",
        "                               text_length: int) -> List[Tuple[str, float]]:\n",
        "        \"\"\"\n",
        "        Calculate quality scores for each phrase.\n",
        "\n",
        "        Args:\n",
        "            phrases: List of (phrase, frequency) tuples\n",
        "            text_length: Total word count of original text\n",
        "\n",
        "        Returns:\n",
        "            List of (phrase, score) tuples, sorted by score\n",
        "        \"\"\"\n",
        "        scored_phrases = []\n",
        "\n",
        "        # Get max frequency for normalization\n",
        "        max_freq = max([freq for _, freq in phrases]) if phrases else 1\n",
        "\n",
        "        for phrase, freq in phrases:\n",
        "            # Initialize scores\n",
        "            scores = {\n",
        "                'frequency': 0.0,\n",
        "                'specificity': 0.0,\n",
        "                'length': 0.0,\n",
        "                'domain_relevance': 0.0,\n",
        "                'completeness': 0.0\n",
        "            }\n",
        "\n",
        "            # 1. Frequency score (normalized, with diminishing returns)\n",
        "            scores['frequency'] = min(freq / max_freq, 1.0) * 0.3\n",
        "\n",
        "            # 2. Specificity score (penalize generic phrases)\n",
        "            words = phrase.lower().split()\n",
        "            generic_count = sum(1 for word in words if word in self.generic_words)\n",
        "            scores['specificity'] = (1 - generic_count / len(words)) * 0.25\n",
        "\n",
        "            # 3. Length score (prefer 2-3 word phrases)\n",
        "            if len(words) == 1:\n",
        "                scores['length'] = 0.7\n",
        "            elif len(words) == 2:\n",
        "                scores['length'] = 1.0\n",
        "            elif len(words) == 3:\n",
        "                scores['length'] = 0.9\n",
        "            else:\n",
        "                scores['length'] = 0.5\n",
        "            scores['length'] *= 0.15\n",
        "\n",
        "            # 4. Domain relevance (contains domain-specific terms)\n",
        "            domain_word_count = sum(1 for word in words\n",
        "                                  if word in self.domain_indicators)\n",
        "            scores['domain_relevance'] = min(domain_word_count / len(words), 1.0) * 0.2\n",
        "\n",
        "            # 5. Completeness score (avoid partial phrases)\n",
        "            # Check if phrase seems complete (not starting/ending with common connectors)\n",
        "            incomplete_markers = {'of', 'to', 'for', 'with', 'and', 'or', 'but'}\n",
        "            is_complete = (words[0] not in incomplete_markers and\n",
        "                          words[-1] not in incomplete_markers)\n",
        "            scores['completeness'] = 1.0 if is_complete else 0.5\n",
        "            scores['completeness'] *= 0.1\n",
        "\n",
        "            # Calculate total score\n",
        "            total_score = sum(scores.values())\n",
        "\n",
        "            # Bonus for exact domain matches\n",
        "            if phrase.lower() in {'a/b testing', 'content writing', 'social media',\n",
        "                                 'email marketing', 'data analysis'}:\n",
        "                total_score *= 1.2\n",
        "\n",
        "            scored_phrases.append((phrase, total_score))\n",
        "\n",
        "        # Sort by score (descending)\n",
        "        scored_phrases.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return scored_phrases\n",
        "\n",
        "\n",
        "    def filter_similar_phrases(self, scored_phrases: List[Tuple[str, float]],\n",
        "                              similarity_threshold: float = 0.5) -> List[Tuple[str, float]]:\n",
        "        \"\"\"\n",
        "        Remove similar/redundant phrases, keeping the highest scoring variant.\n",
        "\n",
        "        Args:\n",
        "            scored_phrases: List of (phrase, score) tuples\n",
        "            similarity_threshold: Threshold for considering phrases similar (lowered to 0.5)\n",
        "\n",
        "        Returns:\n",
        "            Filtered list of (phrase, score) tuples\n",
        "        \"\"\"\n",
        "        filtered = []\n",
        "        selected_phrases = []  # Store actual phrases for substring checking\n",
        "\n",
        "        for phrase, score in scored_phrases:\n",
        "            phrase_lower = phrase.lower()\n",
        "\n",
        "            # Check if this phrase is redundant\n",
        "            is_redundant = False\n",
        "\n",
        "            for selected in selected_phrases:\n",
        "                selected_lower = selected.lower()\n",
        "\n",
        "                # Check if one phrase is a substring of another\n",
        "                if phrase_lower in selected_lower or selected_lower in phrase_lower:\n",
        "                    # Keep the longer, more specific phrase\n",
        "                    is_redundant = True\n",
        "                    break\n",
        "\n",
        "                # Also check word set overlap\n",
        "                words1 = set(phrase_lower.split())\n",
        "                words2 = set(selected_lower.split())\n",
        "\n",
        "                if len(words1) > 0 and len(words2) > 0:\n",
        "                    intersection = words1.intersection(words2)\n",
        "                    smaller_set_size = min(len(words1), len(words2))\n",
        "\n",
        "                    # If most words overlap, consider redundant\n",
        "                    if len(intersection) / smaller_set_size >= similarity_threshold:\n",
        "                        is_redundant = True\n",
        "                        break\n",
        "\n",
        "            if not is_redundant:\n",
        "                filtered.append((phrase, score))\n",
        "                selected_phrases.append(phrase)\n",
        "\n",
        "        return filtered"
      ],
      "metadata": {
        "id": "037iMS-hi-61"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_phrase_scorer():\n",
        "    # First extract phrases\n",
        "    extractor = KeyPhraseExtractor()\n",
        "    test_text = \"\"\"\n",
        "    Creating social media posts is a great way to hone your content writing skills.\n",
        "    Since posts are typically very short, snappy, and quick, you can easily try out\n",
        "    different styles of writing and see what people respond to. It's easy to change\n",
        "    direction and adapt if you need to tweak your writing style since social media\n",
        "    posts are typically fluid and changeable by nature. You can also practice A/B\n",
        "    testing with your social media ads—try writing two different posts and sending\n",
        "    it to similar demographics and see which one performs better.\n",
        "    \"\"\"\n",
        "\n",
        "    phrases = extractor.extract_phrases(test_text)\n",
        "\n",
        "    # Score and filter phrases\n",
        "    scorer = PhraseScorer()\n",
        "    word_count = len(test_text.split())\n",
        "\n",
        "    scored_phrases = scorer.calculate_phrase_scores(phrases, word_count)\n",
        "    filtered_phrases = scorer.filter_similar_phrases(scored_phrases)\n",
        "\n",
        "    print(\"\\nTop scored phrases (before filtering):\")\n",
        "    for phrase, score in scored_phrases[:10]:\n",
        "        print(f\"  '{phrase}' - Score: {score:.3f}\")\n",
        "\n",
        "    print(\"\\nFiltered phrases (after removing similar ones):\")\n",
        "    for phrase, score in filtered_phrases[:10]:\n",
        "        print(f\"  '{phrase}' - Score: {score:.3f}\")\n",
        "\n",
        "    print(\"\\nFinal tags for this text:\")\n",
        "    # Select tags with score > 0.6 or top 7, whichever is less\n",
        "    quality_tags = [(phrase, score) for phrase, score in filtered_phrases if score > 0.6]\n",
        "    if len(quality_tags) < 5:\n",
        "        quality_tags = filtered_phrases[:7]\n",
        "    else:\n",
        "        quality_tags = quality_tags[:7]\n",
        "\n",
        "    final_tags = [phrase for phrase, score in quality_tags]\n",
        "    print(f\"  {', '.join(final_tags)}\")"
      ],
      "metadata": {
        "id": "ShAawqeWjBq3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the test\n",
        "if __name__ == \"__main__\":\n",
        "    test_phrase_scorer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vSPV7p5jXAI",
        "outputId": "557a0486-2de5-41cb-b56f-1126ba70f4f9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyPhraseExtractor initialized successfully\n",
            "PhraseScorer initialized successfully\n",
            "\n",
            "Top scored phrases (before filtering):\n",
            "  'social media' - Score: 1.110\n",
            "  'writing' - Score: 0.955\n",
            "  'media' - Score: 0.880\n",
            "  'posts' - Score: 0.755\n",
            "  'content' - Score: 0.730\n",
            "  'testing' - Score: 0.730\n",
            "  'social media posts' - Score: 0.693\n",
            "  'social media ads' - Score: 0.693\n",
            "  'media posts' - Score: 0.675\n",
            "  'writing style' - Score: 0.675\n",
            "\n",
            "Filtered phrases (after removing similar ones):\n",
            "  'social media' - Score: 1.110\n",
            "  'writing' - Score: 0.955\n",
            "  'posts' - Score: 0.755\n",
            "  'content' - Score: 0.730\n",
            "  'testing' - Score: 0.730\n",
            "  'similar demographics' - Score: 0.575\n",
            "  'creating' - Score: 0.530\n",
            "  'skills' - Score: 0.530\n",
            "  'styles' - Score: 0.530\n",
            "  'ads' - Score: 0.530\n",
            "\n",
            "Final tags for this text:\n",
            "  social media, writing, posts, content, testing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DynamicTagger:\n",
        "    \"\"\"\n",
        "    Complete dynamic tagging system that:\n",
        "    1. Extracts key phrases from any text\n",
        "    2. Scores them based on quality metrics\n",
        "    3. Uses semantic embeddings to ensure relevance\n",
        "    4. Returns the best tags for any domain\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder_model=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "        print(\"Initializing DynamicTagger...\")\n",
        "\n",
        "        # Initialize all components\n",
        "        self.encoder = TextEncoder(encoder_model)\n",
        "        self.extractor = KeyPhraseExtractor()\n",
        "        self.scorer = PhraseScorer()\n",
        "\n",
        "        print(\"DynamicTagger ready!\")\n",
        "\n",
        "    def generate_tags(self, text: str, max_tags: int = 10, min_score: float = 0.6) -> List[Tuple[str, float]]:\n",
        "        \"\"\"\n",
        "        Generate tags dynamically from input text.\n",
        "\n",
        "        Args:\n",
        "            text: Input text to generate tags from\n",
        "            max_tags: Maximum number of tags to return\n",
        "            min_score: Minimum quality score for tags\n",
        "\n",
        "        Returns:\n",
        "            List of (tag, relevance_score) tuples\n",
        "        \"\"\"\n",
        "        # Step 1: Extract key phrases\n",
        "        phrases = self.extractor.extract_phrases(text)\n",
        "\n",
        "        if not phrases:\n",
        "            return []\n",
        "\n",
        "        # Step 2: Score phrases for quality\n",
        "        word_count = len(text.split())\n",
        "        scored_phrases = self.scorer.calculate_phrase_scores(phrases, word_count)\n",
        "\n",
        "        # Step 3: Filter redundant phrases\n",
        "        filtered_phrases = self.scorer.filter_similar_phrases(scored_phrases)\n",
        "\n",
        "        # Step 4: Apply semantic relevance using embeddings\n",
        "        text_embedding = self.encoder.encode_text(text)\n",
        "\n",
        "        # Combine quality score with semantic relevance\n",
        "        final_scores = []\n",
        "        for phrase, quality_score in filtered_phrases:\n",
        "            # Get semantic similarity between phrase and full text\n",
        "            phrase_embedding = self.encoder.encode_text(phrase)\n",
        "\n",
        "            # Calculate cosine similarity\n",
        "            semantic_score = cosine_similarity(\n",
        "                text_embedding.reshape(1, -1),\n",
        "                phrase_embedding.reshape(1, -1)\n",
        "            )[0][0]\n",
        "\n",
        "            # Combine scores (70% quality, 30% semantic)\n",
        "            combined_score = (quality_score * 0.7) + (semantic_score * 0.3)\n",
        "\n",
        "            final_scores.append((phrase, combined_score))\n",
        "\n",
        "        # Sort by combined score\n",
        "        final_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Apply quality threshold\n",
        "        quality_tags = [(tag, score) for tag, score in final_scores if score > min_score]\n",
        "\n",
        "        # Ensure minimum number of tags\n",
        "        if len(quality_tags) < 5 and len(final_scores) >= 5:\n",
        "            quality_tags = final_scores[:5]\n",
        "\n",
        "        # Return up to max_tags\n",
        "        return quality_tags[:max_tags]\n",
        "\n",
        "    def tag_text(self, text: str, max_tags: int = 7) -> List[str]:\n",
        "        \"\"\"\n",
        "        Simple interface that returns just the tag strings.\n",
        "\n",
        "        Args:\n",
        "            text: Input text to tag\n",
        "            max_tags: Maximum number of tags\n",
        "\n",
        "        Returns:\n",
        "            List of tag strings\n",
        "        \"\"\"\n",
        "        tag_scores = self.generate_tags(text, max_tags)\n",
        "        return [tag for tag, _ in tag_scores]\n",
        "\n",
        "\n",
        "    def tag_text_with_scores(self, text: str, max_tags: int = 7) -> List[Tuple[str, float]]:\n",
        "        \"\"\"\n",
        "        Interface that returns tags with their scores.\n",
        "\n",
        "        Args:\n",
        "            text: Input text to tag\n",
        "            max_tags: Maximum number of tags\n",
        "\n",
        "        Returns:\n",
        "            List of (tag, score) tuples\n",
        "        \"\"\"\n",
        "        return self.generate_tags(text, max_tags)"
      ],
      "metadata": {
        "id": "dvWe8FKHm0KM"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_dynamic_tagger():\n",
        "    tagger = DynamicTagger()\n",
        "\n",
        "    # Test 1: Original social media text\n",
        "    print(\"=\"*60)\n",
        "    print(\"Test 1: Social Media Marketing Text\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    test_text1 = \"\"\"\n",
        "    Creating social media posts is a great way to hone your content writing skills.\n",
        "    Since posts are typically very short, snappy, and quick, you can easily try out\n",
        "    different styles of writing and see what people respond to. It's easy to change\n",
        "    direction and adapt if you need to tweak your writing style since social media\n",
        "    posts are typically fluid and changeable by nature. You can also practice A/B\n",
        "    testing with your social media ads—try writing two different posts and sending\n",
        "    it to similar demographics and see which one performs better.\n",
        "    \"\"\"\n",
        "\n",
        "    tags1 = tagger.tag_text_with_scores(test_text1)\n",
        "    for tag, score in tags1:\n",
        "        print(f\"  '{tag}' - Score: {score:.3f}\")\n",
        "\n",
        "\n",
        "    # Test 2: Technical content\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Test 2: Technical/Programming Text\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    test_text2 = \"\"\"\n",
        "    Machine learning algorithms are transforming how we process bigdata. Python\n",
        "    libraries like TensorFlow and PyTorch make it easier to build neural networks\n",
        "    for deep learning applications. Data scientists use these tools for predictive\n",
        "    analytics and pattern recognition in complex datasets.\n",
        "    \"\"\"\n",
        "\n",
        "    tags2 = tagger.tag_text_with_scores(test_text2)\n",
        "    for tag, score in tags2:\n",
        "        print(f\"  '{tag}' - Score: {score:.3f}\")\n",
        "\n",
        "    # Test 3: Medical content\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Test 3: Medical/Healthcare Text\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    test_text3 = \"\"\"\n",
        "    The patient presented with acute respiratory symptoms including persistent cough\n",
        "    and shortness of breath. Blood tests revealed elevated white blood cell count.\n",
        "    Treatment protocol included antibiotics and respiratory therapy. Follow-up\n",
        "    examination showed significant improvement in lung function.\n",
        "    \"\"\"\n",
        "\n",
        "    tags3 = tagger.tag_text_with_scores(test_text3)\n",
        "    print(\"\\nFinal tags with scores:\")\n",
        "    for tag, score in tags3:\n",
        "        print(f\"  '{tag}' - Score: {score:.3f}\")\n",
        "\n",
        "\n",
        "    # Test 4: my eg test\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Test 4: My Random Example\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    test_text4 = \"\"\"\n",
        "    We are pleased to announce that the Viewfinders Club is now welcoming new volunteers\n",
        "    who are passionate about photography and eager to contribute to capturing the vibrant\n",
        "    moments of our school life.\n",
        "    \"\"\"\n",
        "\n",
        "    tags4 = tagger.tag_text_with_scores(test_text4)\n",
        "    print(\"\\nFinal tags with scores:\")\n",
        "    for tag, score in tags4:\n",
        "        print(f\"  '{tag}' - Score: {score:.3f}\")"
      ],
      "metadata": {
        "id": "32hlQqdXsbKj"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the test\n",
        "if __name__ == \"__main__\":\n",
        "    test_dynamic_tagger()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KoVWkgmseuf",
        "outputId": "f284906f-7def-4e2e-ba20-f4dd7a6d682e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing DynamicTagger...\n",
            "Model Loaded Succesfully\n",
            "KeyPhraseExtractor initialized successfully\n",
            "PhraseScorer initialized successfully\n",
            "DynamicTagger ready!\n",
            "============================================================\n",
            "Test 1: Social Media Marketing Text\n",
            "============================================================\n",
            "  'social media' - Score: 0.922\n",
            "  'writing' - Score: 0.766\n",
            "  'posts' - Score: 0.634\n",
            "  'content' - Score: 0.587\n",
            "  'testing' - Score: 0.555\n",
            "\n",
            "============================================================\n",
            "Test 2: Technical/Programming Text\n",
            "============================================================\n",
            "  'data' - Score: 0.660\n",
            "  'learning' - Score: 0.631\n",
            "  'tensorflow' - Score: 0.593\n",
            "  'neural networks' - Score: 0.570\n",
            "  'pytorch' - Score: 0.553\n",
            "\n",
            "============================================================\n",
            "Test 3: Medical/Healthcare Text\n",
            "============================================================\n",
            "\n",
            "Final tags with scores:\n",
            "  'persistent cough' - Score: 0.629\n",
            "  'respiratory symptoms' - Score: 0.613\n",
            "  'blood' - Score: 0.584\n",
            "  'lung function' - Score: 0.553\n",
            "  'breath' - Score: 0.512\n",
            "\n",
            "============================================================\n",
            "Test 4: My Random Example\n",
            "============================================================\n",
            "\n",
            "Final tags with scores:\n",
            "  'viewfinders club' - Score: 0.766\n",
            "  'volunteers' - Score: 0.668\n",
            "  'photography' - Score: 0.653\n",
            "  'welcoming' - Score: 0.652\n",
            "  'capturing' - Score: 0.619\n",
            "  'school life' - Score: 0.610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K1XpOem5skih"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}